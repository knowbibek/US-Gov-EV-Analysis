# -*- coding: utf-8 -*-
"""big data project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B7TcJ6VcGh-TeGbq3KMHvIiU3xhp4nEg
"""

# Install Java
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# Download Spark 3.3.2 (working mirror)
!wget -q https://archive.apache.org/dist/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz

# Extract Spark
!tar -xvzf spark-3.3.2-bin-hadoop3.tgz

# Install findspark
!pip install -q findspark

import os
import findspark

os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.3.2-bin-hadoop3"

findspark.init()

from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("US Gov Spending Analysis") \
    .getOrCreate()

spark

from google.colab import files
uploaded = files.upload()

df = spark.read.csv("gov_spending.csv", header=True, inferSchema=True)
df.show()

df = spark.read.csv("gov_spending.csv", header=True, inferSchema=True)
df.show()

# Drop any rows with missing values (if needed)
df_clean = df.dropna()

# View data types
df_clean.printSchema()

# Optional: Show total number of rows
print("Total Records:", df_clean.count())

df_clean.groupBy("Make").count().orderBy("count", ascending=False).show()

df_clean.groupBy("Model Year").count().orderBy("Model Year").show()

df_clean.groupBy("City").count().orderBy("count", ascending=False).show(10)

df_clean.groupBy("Electric Vehicle Type").count().orderBy("count", ascending=False).show()

df_clean.groupBy("County").count().orderBy("count", ascending=False).show()

import matplotlib.pyplot as plt
import pandas as pd

top_makes = df_clean.groupBy("Make").count().orderBy("count", ascending=False).limit(10).toPandas()

plt.figure(figsize=(10,6))
plt.bar(top_makes['Make'], top_makes['count'])
plt.title("Top 10 EV Makes in Washington")
plt.xticks(rotation=45)
plt.xlabel("Make")
plt.ylabel("Count")
plt.tight_layout()
plt.show()

!apt-get install graphviz -qq
!pip install graphviz

from graphviz import Digraph

dot = Digraph()

dot.attr(rankdir='LR')  # Left to Right layout

# Define nodes
dot.node('A', 'CSV File\n(gov_spending.csv)')
dot.node('B', 'Google Colab')
dot.node('C', 'PySpark DataFrame')
dot.node('D', 'Data Cleaning\n& Aggregation')
dot.node('E', 'Spark Analysis\n(Year, Make, City, Type)')
dot.node('F', 'Visualizations\n(Matplotlib Charts)')
dot.node('G', 'Insights\n& Trends')

# Define edges
dot.edge('A', 'B')
dot.edge('B', 'C')
dot.edge('C', 'D')
dot.edge('D', 'E')
dot.edge('E', 'F')
dot.edge('F', 'G')

# Display the diagram
dot.render('pipeline_diagram', format='png', cleanup=False)
dot